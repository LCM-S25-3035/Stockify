{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852fa46a-ccfc-46e3-84b5-8416a2a3cab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV columns: ['Crypto', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "Using price columns: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneh_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 634  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 3    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 408         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006664174 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.09       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00835     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 0.0379      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 364          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052799233 |\n",
      "|    clip_fraction        | 0.0717       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.07        |\n",
      "|    explained_variance   | 0.812        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0566       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 0.0901       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005273926 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.07       |\n",
      "|    explained_variance   | 0.00129     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0559      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 339          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055943253 |\n",
      "|    clip_fraction        | 0.0594       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.09        |\n",
      "|    explained_variance   | 0.0112       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0553       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.122        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 332          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051549785 |\n",
      "|    clip_fraction        | 0.0447       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.06        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.239        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    std                  | 0.989        |\n",
      "|    value_loss           | 0.976        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+04    |\n",
      "|    ep_rew_mean          | 209         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 329         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005528045 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.03       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.515       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 0.617       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.34e+04     |\n",
      "|    ep_rew_mean          | 209          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 325          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075707394 |\n",
      "|    clip_fraction        | 0.077        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.99        |\n",
      "|    explained_variance   | 0.0522       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0427       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 0.148        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+04    |\n",
      "|    ep_rew_mean          | 209         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005719352 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.96       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0321      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.34e+04     |\n",
      "|    ep_rew_mean          | 209          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 320          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071632606 |\n",
      "|    clip_fraction        | 0.0878       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.94        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0412       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 0.121        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.34e+04     |\n",
      "|    ep_rew_mean          | 209          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 319          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070453444 |\n",
      "|    clip_fraction        | 0.0722       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.94        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0346       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 0.146        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.34e+04     |\n",
      "|    ep_rew_mean          | 209          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 317          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053689214 |\n",
      "|    clip_fraction        | 0.0542       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.9         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.101        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    std                  | 0.954        |\n",
      "|    value_loss           | 0.353        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+04    |\n",
      "|    ep_rew_mean          | 209         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005150689 |\n",
      "|    clip_fraction        | 0.052       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.87       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.311       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    std                  | 0.958       |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+04    |\n",
      "|    ep_rew_mean          | 228         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006467323 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.85       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0947      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    std                  | 0.947       |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+04    |\n",
      "|    ep_rew_mean          | 228         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009332554 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.8        |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0384      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.941       |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from stable_baselines3 import PPO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CSV data\n",
    "df = pd.read_csv(\"cleaned_crypto_data.csv\", parse_dates=['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Print columns to check their names\n",
    "print(\"CSV columns:\", df.columns.tolist())\n",
    "\n",
    "# Automatically select numeric columns for prices (crypto + ETFs)\n",
    "price_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"Using price columns:\", price_columns)\n",
    "prices_df = df[price_columns]\n",
    "\n",
    "prices = prices_df.values\n",
    "\n",
    "# Normalize prices for use in environment\n",
    "scaler = MinMaxScaler()\n",
    "prices_norm = scaler.fit_transform(prices)\n",
    "\n",
    "# Create dummy micro indicators (zeros, or add your own indicators)\n",
    "micro_indicators = np.zeros_like(prices)\n",
    "\n",
    "# Create dummy regime (0 = bullish)\n",
    "regime_classes = np.zeros(len(prices), dtype=int)\n",
    "\n",
    "class PortfolioEnv(gym.Env):\n",
    "    def __init__(self, prices, regimes, indicators, initial_balance=10000, fee=0.001):\n",
    "        super().__init__()\n",
    "        self.prices = prices\n",
    "        self.regimes = regimes\n",
    "        self.indicators = indicators\n",
    "        self.initial_balance = initial_balance\n",
    "        self.transaction_fee = fee\n",
    "\n",
    "        self.n_assets = prices.shape[1]\n",
    "        self.num_regimes = 3\n",
    "\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.n_assets,), dtype=np.float32)\n",
    "        obs_dim = self.n_assets + 2 + self.num_regimes + self.indicators.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_idx = 0\n",
    "        self.portfolio_value = self.initial_balance\n",
    "        self.weights = np.ones(self.n_assets) / self.n_assets\n",
    "        self.holdings = (self.portfolio_value * self.weights) / self.prices[self.step_idx]\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        regime_onehot = np.zeros(self.num_regimes)\n",
    "        regime_onehot[self.regimes[self.step_idx]] = 1\n",
    "        obs = np.concatenate([\n",
    "            self.prices[self.step_idx] / (self.prices[0] + 1e-8),\n",
    "            [self.portfolio_value / self.initial_balance],\n",
    "            [0.5],  # risk appetite (fixed)\n",
    "            regime_onehot,\n",
    "            self.indicators[self.step_idx]\n",
    "        ])\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        action = np.clip(action, 0, 1)\n",
    "        new_weights = action / (np.sum(action) + 1e-8)  # normalize weights\n",
    "\n",
    "        transaction_cost = np.sum(np.abs(self.weights - new_weights)) * self.portfolio_value * self.transaction_fee\n",
    "        self.portfolio_value -= transaction_cost\n",
    "\n",
    "        self.weights = new_weights\n",
    "        next_prices = self.prices[self.step_idx + 1]\n",
    "        current_prices = self.prices[self.step_idx]\n",
    "        returns = (next_prices - current_prices) / (current_prices + 1e-8)  # avoid div by zero\n",
    "\n",
    "        portfolio_return = np.dot(self.weights, returns)\n",
    "        reward = portfolio_return - transaction_cost / max(self.portfolio_value, 1e-8)\n",
    "        self.portfolio_value *= (1 + portfolio_return)\n",
    "\n",
    "        self.step_idx += 1\n",
    "        done = self.step_idx >= len(self.prices) - 2\n",
    "        return self._get_obs(), reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        print(f\"Step {self.step_idx}, Portfolio Value: {self.portfolio_value:.2f}\")\n",
    "\n",
    "# Create and train environment\n",
    "env = PortfolioEnv(prices_norm, regime_classes, micro_indicators)\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=50000)\n",
    "\n",
    "# Evaluate\n",
    "obs = env.reset()\n",
    "rewards, values = [], [env.portfolio_value]\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    values.append(env.portfolio_value)\n",
    "\n",
    "# Plot portfolio value over time\n",
    "plt.plot(values)\n",
    "plt.title(\"Portfolio Value Over Time\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Value ($)\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
